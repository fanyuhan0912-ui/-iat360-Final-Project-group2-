{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawitphoom/-iat360-Final-Project-group2-/blob/main/another_copy_of_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toxic Comment Detection: Fine-Tuning DistilBERT with Data Augmentation and Bias Mitigation"
      ],
      "metadata": {
        "id": "ILDK-i8K-z2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project fine-tunes a DistilBERT model to classify multi-label toxic comments. To address the rubric requirements, this pipeline includes:\n",
        "\n",
        "- Data Augmentation: improving the raw dataset using synonym replacement for minority classes (Paraphrasing strategy).\n",
        "\n",
        "- Class Imbalance Handling: Implementing a Custom Trainer with Weighted Loss (Focal/BCE with pos_weights).\n",
        "\n",
        "- Bias Evaluation: Analyzing model performance on identity-specific terms to detect unintended bias."
      ],
      "metadata": {
        "id": "mnvunpQz-5bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Check GPU Availability"
      ],
      "metadata": {
        "id": "Kj9Y9Q8pQCyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block initializes the environment required for training the toxic comment classification model. It performs three main tasks: verifying hardware and library versions, ensuring necessary NLP resources are available, and defining dataset paths and target labels."
      ],
      "metadata": {
        "id": "wDMWft7iqmXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "# --- INSTALLATION COMMANDS (Uncomment if running on a new machine) ---\n",
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install nlpaug pandas scikit-learn transformers\n",
        "\n",
        "# --- 1. Check Hardware & Versions ---\n",
        "print(f\"Python Version: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"WARNING: You are running on CPU. Training will be slow.\")\n",
        "\n",
        "# --- 2. Download NLTK Data (Quietly) ---\n",
        "print(\"\\nVerifying NLTK data...\")\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet.zip')\n",
        "    nltk.data.find('corpora/omw-1.4.zip')\n",
        "    print(\" NLTK Data already installed.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK data...\")\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "    print(\" NLTK Data downloaded.\")\n",
        "\n",
        "# --- 3. Define Data Paths ---\n",
        "# Update this path if you move the notebook to a different computer\n",
        "TRAIN_CSV = \"/content/train.csv\"\n",
        "DATA_DIR = os.path.dirname(TRAIN_CSV) # Define DATA_DIR here\n",
        "\n",
        "# Define the labels we are predicting\n",
        "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "\n",
        "print(f\"\\nData Directory: {DATA_DIR}\")\n",
        "print(f\"Target Labels: {label_cols}\")"
      ],
      "metadata": {
        "id": "ujcA91YKzVU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup & Library Installation\n",
        "This code block ensures that all required NLTK linguistic resources are available before performing synonym-based data augmentation. Since the augmentation method relies heavily on WordNet for retrieving synonyms and on POS tagging for generating grammatically appropriate replacements, several NLTK corpora must be downloaded and verified.\n",
        "\n",
        "First, the script downloads the necessary resources:\n",
        "\n",
        "wordnet — the core lexical database used for synonym lookup\n",
        "\n",
        "omw-1.4 — a dependency required by recent versions of NLTK for multilingual WordNet support\n",
        "\n",
        "averaged_perceptron_tagger — the POS tagger needed by augmentation tools to identify word types\n",
        "\n",
        "punkt / punkt_tab — tokenization models used for sentence and word segmentation\n",
        "\n",
        "After downloading these datasets, the script loads the WordNet corpus and verifies its functionality by querying a sample synset. This validation step ensures that the environment is fully prepared for synonym replacement operations. Proper installation of these resources prevents augmentation failures and guarantees that the data preprocessing pipeline can run reliably."
      ],
      "metadata": {
        "id": "I8QtXAvQMRGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download ALL necessary NLTK data (including the missing 'omw-1.4')\n",
        "print(\"Downloading NLTK data...\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')                    # <--- This is likely the missing piece!\n",
        "nltk.download('averaged_perceptron_tagger') # Required for SynonymAug\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')                  # Newer versions of NLTK sometimes need this\n",
        "\n",
        "# Verify WordNet works before nlpaug uses it\n",
        "from nltk.corpus import wordnet\n",
        "try:\n",
        "    wordnet.synsets('test')\n",
        "    print(\" WordNet loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\" WordNet failed: {e}\")"
      ],
      "metadata": {
        "id": "-GMBM84TF8X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Loading & Exploratory Analysis\n",
        "We load the Jigsaw Toxic Comment Classification dataset. We perform a quick exploratory data analysis (EDA) to visualize the distribution of the six toxicity labels, confirming the significant class imbalance that needs addressing."
      ],
      "metadata": {
        "id": "LHuXuX6eMZ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "print(\"Rows:\", len(df))\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nLabel counts:\")\n",
        "print(df[label_cols].sum())"
      ],
      "metadata": {
        "id": "VxEVZtNCZFJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Augmentation (Dataset Contribution)\n",
        "To address the \"Improve the raw dataset\" requirement, we implement a Data Augmentation pipeline using `nlpaug`. We use synonym replacement (via WordNet) to generate synthetic examples for the minority classes (Threat, Severe Toxic, Identity Hate). This helps the model generalize better on underrepresented data."
      ],
      "metadata": {
        "id": "wXr5S1joMeTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Initialize Augmenter\n",
        "# Note: If 'wordnet' still fails, you can try aug_src='ppdb' (but it requires a different download)\n",
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "# 2. Select minority classes\n",
        "minority_cols = ['threat', 'severe_toxic', 'identity_hate']\n",
        "\n",
        "# 3. Create augmented data\n",
        "augmented_rows = []\n",
        "rows_to_augment = df[df[minority_cols].sum(axis=1) > 0].sample(n=500, random_state=42)\n",
        "\n",
        "print(\"Augmenting rows...\")\n",
        "\n",
        "for idx, row in rows_to_augment.iterrows():\n",
        "    original_text = row['comment_text']\n",
        "    try:\n",
        "        augmented_text = aug.augment(original_text)\n",
        "        # Verify list vs string return type\n",
        "        if isinstance(augmented_text, list):\n",
        "            augmented_text = augmented_text[0]\n",
        "\n",
        "        new_row = row.copy()\n",
        "        new_row['comment_text'] = augmented_text\n",
        "        augmented_rows.append(new_row)\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "# 4. Merge\n",
        "aug_df = pd.DataFrame(augmented_rows)\n",
        "df = pd.concat([df, aug_df]).reset_index(drop=True)\n",
        "\n",
        "print(f\"New Dataset Size: {len(df)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NGMTe1QhGaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Split & Tokenization\n",
        "We split the enhanced dataset into Train (70%), Validation (15%), and Test (15%) sets. We then implement a custom PyTorch `Dataset` class and tokenize the text using the `DistilBertTokenizerFast`, truncating sequences to 128 tokens for efficiency."
      ],
      "metadata": {
        "id": "cl9eoqwZZ7rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))"
      ],
      "metadata": {
        "id": "e3IZRpJUZ83A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df[\"comment_text\"].tolist()\n",
        "        self.labels = df[label_cols].values.astype(\"float32\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx]),\n",
        "        }\n",
        "\n",
        "train_dataset = ToxicDataset(train_df)\n",
        "val_dataset   = ToxicDataset(val_df)\n",
        "test_dataset  = ToxicDataset(test_df)\n",
        "\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)\n"
      ],
      "metadata": {
        "id": "2UoTBOxDaDDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Initialization & Metric Definition\n",
        "\n",
        "We initialize a pre-trained `DistilBERT` model for multi-label sequence classification. We define a compute_metrics function that calculates Micro-F1, Macro-F1, and ROC-AUC scores to evaluate model performance across all labels."
      ],
      "metadata": {
        "id": "SdferkwPMpL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=6,\n",
        "    problem_type=\"multi_label_classification\",\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-logits))      # sigmoid\n",
        "    preds = (probs > 0.5).astype(int)      # threshold 0.5\n",
        "\n",
        "    micro_f1 = f1_score(labels, preds, average=\"micro\", zero_division=0)\n",
        "    macro_f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, probs, average=\"macro\")\n",
        "    except ValueError:\n",
        "        auc = 0.0\n",
        "\n",
        "    return {\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"auc\": auc,\n",
        "    }"
      ],
      "metadata": {
        "id": "NXbPig2KaG2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Class Weight Calculation\n",
        "\n",
        "To prepare for our technical contribution (Weighted Loss), we calculate inverse class frequencies. Rare classes like \"Threat\" receive higher weights, while common classes like \"Toxic\" receive lower weights."
      ],
      "metadata": {
        "id": "kfoCa3kjaUbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights for the Weighted Loss\n",
        "label_counts = train_df[label_cols].sum().values\n",
        "total = len(train_df)\n",
        "neg_counts = total - label_counts\n",
        "pos_counts = label_counts\n",
        "\n",
        "# Calculate weights: Negative samples / Positive samples\n",
        "class_weights = neg_counts / (pos_counts + 1e-6)\n",
        "\n",
        "print(\"Class weights calculated:\", class_weights)"
      ],
      "metadata": {
        "id": "MNAnMnGlHnQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define the missing training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,              # 2 epochs (from your previous screenshots)\n",
        "    per_device_train_batch_size=16,  # Batch size 16\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",           # Evaluate every epoch\n",
        "    save_strategy=\"epoch\",           # Save every epoch\n",
        "    load_best_model_at_end=True,     # Keep the best model\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=100,\n",
        "    fp16=True,                       # Use Mixed Precision (Faster on your RTX 4080)\n",
        ")"
      ],
      "metadata": {
        "id": "n0k1cOq0H5IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 Baseline Model Training (Without Class Weights)"
      ],
      "metadata": {
        "id": "ZtOADqp4_VdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.1.1 Initialize Baseline Model"
      ],
      "metadata": {
        "id": "XFup1dwe_mtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=6,\n",
        "    problem_type=\"multi_label_classification\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "7t4i0qFt_e_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.1.2 Train Baseline Model"
      ],
      "metadata": {
        "id": "8VztsfXh_5hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "baseline_trainer = Trainer(\n",
        "    model=baseline_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Starting baseline training (no class weights)...\")\n",
        "baseline_trainer.train()\n"
      ],
      "metadata": {
        "id": "ie8ZF1HJ_-um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.3 Evaluate Baseline Model on Test Set"
      ],
      "metadata": {
        "id": "NHTrNEMfAHrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_eval = baseline_trainer.evaluate(test_dataset)\n",
        "baseline_eval\n"
      ],
      "metadata": {
        "id": "xatEeHv_AMZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Custom Weighted Loss Trainer (Technical Contribution)\n",
        "\n",
        "Standard Cross-Entropy loss struggles with imbalanced data. Here, we implement a **Custom Trainer** that overrides the `compute_loss` method. We replace the standard loss with `BCEWithLogitsLoss` using the positive class weights calculated above. This forces the model to pay more attention to minority classes during optimization."
      ],
      "metadata": {
        "id": "NASj4uT6M2He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from transformers import Trainer\n",
        "\n",
        "# 1. Ensure class weights are tensors and on the correct device\n",
        "# (Make sure you ran the cell that calculates 'class_weights' first!)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 2. Define Custom Trainer\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        # Fetch labels and move to device\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Define Weighted Loss (BCEWithLogitsLoss handles multi-label + sigmoid)\n",
        "        loss_fct = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# 3. Initialize the Custom Trainer\n",
        "weighted_trainer = WeightedLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer, # Use processing_class instead of tokenizer\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting training with Weighted Loss...\")\n",
        "weighted_trainer.train()"
      ],
      "metadata": {
        "id": "_ZHALt7VaSlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Final Evaluation & Per-Label Metrics\n",
        "\n",
        "We evaluate the fine-tuned model on the held-out Test Set. We generate a detailed classification report to analyze Precision, Recall, and F1-score for each of the six toxicity categories individually."
      ],
      "metadata": {
        "id": "0STSrGf5c4L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_trainer.evaluate(test_dataset)\n"
      ],
      "metadata": {
        "id": "G6C8mPtUc2o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Get per-label metrics"
      ],
      "metadata": {
        "id": "FY94pUqNfDOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# get logits and labels for test set\n",
        "pred_output = weighted_trainer.predict(test_dataset)\n",
        "logits = pred_output.predictions\n",
        "labels = pred_output.label_ids\n",
        "\n",
        "probs = 1 / (1 + np.exp(-logits))\n",
        "preds = (probs > 0.5).astype(int)\n",
        "\n",
        "print(\"Micro F1:\", f1_score(labels, preds, average=\"micro\", zero_division=0))\n",
        "print(\"Macro F1:\", f1_score(labels, preds, average=\"macro\", zero_division=0))\n",
        "\n",
        "print(\"\\nPer-label report:\\n\")\n",
        "print(classification_report(\n",
        "    labels, preds,\n",
        "    target_names=label_cols,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "id": "pcViTLJAfB8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Save some example predictions"
      ],
      "metadata": {
        "id": "MnM-2v_UfJKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_reset = test_df.reset_index(drop=True)\n",
        "\n",
        "for i in range(5):\n",
        "    text = test_df_reset.loc[i, \"comment_text\"]\n",
        "    true_labels = [label_cols[j] for j, v in enumerate(labels[i]) if v == 1]\n",
        "    pred_labels = [label_cols[j] for j, v in enumerate(preds[i]) if v == 1]\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"Comment:\", text[:300].replace(\"\\n\",\" \"))\n",
        "    print(\"True labels:\", true_labels)\n",
        "    print(\"Predicted labels:\", pred_labels)\n"
      ],
      "metadata": {
        "id": "RphUraKkfLLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11, Post-Training Optimization: Threshold Tuning"
      ],
      "metadata": {
        "id": "KtORXeXCo16C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Compute class weights (for description in report)"
      ],
      "metadata": {
        "id": "AY_jzq3xo438"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = train_df[label_cols].sum().values\n",
        "total = len(train_df)\n",
        "neg_counts = total - label_counts\n",
        "pos_counts = label_counts\n",
        "\n",
        "class_weights = neg_counts / (pos_counts + 1e-6)\n",
        "class_weights\n"
      ],
      "metadata": {
        "id": "NA8B3W1Vo6Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Threshold tuning on validation set (simple)"
      ],
      "metadata": {
        "id": "z4olC6Tvo7zZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get val predictions\n",
        "val_output = weighted_trainer.predict(val_dataset)\n",
        "val_logits = val_output.predictions\n",
        "val_labels = val_output.label_ids\n",
        "val_probs = 1 / (1 + np.exp(-val_logits))\n",
        "\n",
        "best_thresh = 0.5\n",
        "best_macro = 0\n",
        "\n",
        "for t in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    val_preds_t = (val_probs > t).astype(int)\n",
        "    macro = f1_score(val_labels, val_preds_t, average=\"macro\", zero_division=0)\n",
        "    print(f\"threshold {t}: macro F1 = {macro:.4f}\")\n",
        "    if macro > best_macro:\n",
        "        best_macro = macro\n",
        "        best_thresh = t\n",
        "\n",
        "print(\"Best threshold:\", best_thresh, \"macro F1:\", best_macro)\n"
      ],
      "metadata": {
        "id": "NSVQfKAIo82b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then re-evaluate test with this threshold:"
      ],
      "metadata": {
        "id": "6m6NmRpqo_EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = probs  # already computed above from test logits\n",
        "test_preds_t = (test_probs > best_thresh).astype(int)\n",
        "\n",
        "macro_t = f1_score(labels, test_preds_t, average=\"macro\", zero_division=0)\n",
        "micro_t = f1_score(labels, test_preds_t, average=\"micro\", zero_division=0)\n",
        "\n",
        "print(\"Test micro F1 (tuned):\", micro_t)\n",
        "print(\"Test macro F1 (tuned):\", macro_t)\n"
      ],
      "metadata": {
        "id": "K6UlcVtXo_5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can say in report:\n",
        "\n",
        "“We tuned a global decision threshold on the validation set and slightly improved macro F1 from X to Y.”"
      ],
      "metadata": {
        "id": "yRgwZBLapE-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Per-label metrics cell"
      ],
      "metadata": {
        "id": "z0jTSAbrpoqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred_output = weighted_trainer.predict(test_dataset)\n",
        "logits = pred_output.predictions\n",
        "labels = pred_output.label_ids\n",
        "\n",
        "probs = 1 / (1 + np.exp(-logits))\n",
        "preds = (probs > 0.5).astype(int)\n",
        "\n",
        "print(classification_report(\n",
        "    labels, preds,\n",
        "    target_names=label_cols,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "id": "8COd60T3pZOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Example predictions cell"
      ],
      "metadata": {
        "id": "eV3uME2dpsx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_reset = test_df.reset_index(drop=True)\n",
        "\n",
        "for i in range(5):\n",
        "    text = test_df_reset.loc[i, \"comment_text\"]\n",
        "    true_labels = [label_cols[j] for j, v in enumerate(labels[i]) if v == 1]\n",
        "    pred_labels = [label_cols[j] for j, v in enumerate(preds[i]) if v == 1]\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"Comment:\", text[:300].replace(\"\\n\",\" \"))\n",
        "    print(\"True labels:\", true_labels)\n",
        "    print(\"Predicted labels:\", pred_labels)\n"
      ],
      "metadata": {
        "id": "_El63Wy4puDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show comments with other labels"
      ],
      "metadata": {
        "id": "0dFUVfFnqHkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_reset = test_df.reset_index(drop=True)\n",
        "\n",
        "# find and print comments that have any extra toxic labels\n",
        "for i in range(len(test_df_reset)):\n",
        "    true_labels = [label_cols[j] for j, v in enumerate(labels[i]) if v == 1]\n",
        "    pred_labels = [label_cols[j] for j, v in enumerate(preds[i]) if v == 1]\n",
        "\n",
        "    # show rows where there is more than just 'toxic'\n",
        "    if any(l in true_labels for l in ['insult', 'obscene', 'threat', 'severe_toxic', 'identity_hate']):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Comment:\", test_df_reset.loc[i, \"comment_text\"][:300].replace(\"\\n\",\" \"))\n",
        "        print(\"True labels:\", true_labels)\n",
        "        print(\"Predicted labels:\", pred_labels)\n",
        "        break\n"
      ],
      "metadata": {
        "id": "1AaZCcbRqEjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Qualitative Analysis: Model Predictions\n",
        "\n",
        "We iterate through the test set to visualize specific examples of the model's predictions. We extract one example for each toxicity label to verify that the model can correctly identify distinct types of toxicity (e.g., distinguishing \"Threats\" from \"Insults\").\n",
        "\n",
        "#### Show ONE example for EACH label (6 labels)\n"
      ],
      "metadata": {
        "id": "vDBfybk6qEOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_reset = test_df.reset_index(drop=True)\n",
        "\n",
        "found = {\n",
        "    \"toxic\": False,\n",
        "    \"severe_toxic\": False,\n",
        "    \"obscene\": False,\n",
        "    \"threat\": False,\n",
        "    \"insult\": False,\n",
        "    \"identity_hate\": False,\n",
        "}\n",
        "\n",
        "print(\"Collecting examples for each label...\\n\")\n",
        "\n",
        "for i in range(len(test_df_reset)):\n",
        "    true_labels = [label_cols[j] for j, v in enumerate(labels[i]) if v == 1]\n",
        "    pred_labels = [label_cols[j] for j, v in enumerate(preds[i]) if v == 1]\n",
        "\n",
        "    for lbl in true_labels:\n",
        "        if not found[lbl]:\n",
        "            print(\"=\"*90)\n",
        "            print(f\"Label: {lbl}\")\n",
        "            print(\"Comment:\", test_df_reset.loc[i, \"comment_text\"][:300].replace(\"\\n\",\" \"))\n",
        "            print(\"True labels:\", true_labels)\n",
        "            print(\"Predicted labels:\", pred_labels)\n",
        "            print()\n",
        "            found[lbl] = True\n",
        "\n",
        "    # stop when all 6 found\n",
        "    if all(found.values()):\n",
        "        break\n",
        "\n",
        "print(\"\\nDone!\")\n"
      ],
      "metadata": {
        "id": "UjhMu_I_qh-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Bias & Fairness Evaluation (Ethical Analysis)\n",
        "\n",
        "To address ethical considerations, we test the model for **Unintended Identity Bias**. We feed the model synthetic *neutral* sentences containing identity terms (e.g., \"I am a Muslim person\"). If the model predicts these as toxic, it indicates bias in the training data."
      ],
      "metadata": {
        "id": "4U9oU4yYNHky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === BIAS EVALUATION SECTION ===\n",
        "# We check how the model performs on specific identity terms vs general text.\n",
        "# If the model marks non-toxic sentences with \"gay\" or \"muslim\" as toxic, that is bias.\n",
        "\n",
        "identity_terms = ['gay', 'lesbian', 'muslim', 'black', 'white', 'jewish']\n",
        "print(f\"Evaluating bias on terms: {identity_terms}\\n\")\n",
        "\n",
        "def check_bias(model, tokenizer, terms):\n",
        "    results = []\n",
        "\n",
        "    # Create synthetic neutral sentences containing identity terms\n",
        "    neutral_templates = [\n",
        "        \"I am a {term} person.\",\n",
        "        \"The {term} community is large.\",\n",
        "        \"He is {term} and lives in London.\"\n",
        "    ]\n",
        "\n",
        "    for term in terms:\n",
        "        for template in neutral_templates:\n",
        "            text = template.format(term=term)\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(**inputs).logits\n",
        "\n",
        "            # Convert logits to probabilities\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "            # If any label > 0.5, it's a False Positive (Bias)\n",
        "            is_toxic = any(probs > 0.5)\n",
        "            max_prob = max(probs)\n",
        "\n",
        "            results.append({\n",
        "                \"Term\": term,\n",
        "                \"Sentence\": text,\n",
        "                \"Is_Toxic_Pred\": is_toxic,\n",
        "                \"Max_Prob\": f\"{max_prob:.4f}\"\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run the check\n",
        "bias_df = check_bias(model, tokenizer, identity_terms)\n",
        "print(bias_df)"
      ],
      "metadata": {
        "id": "quA9ocquLERO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14. Baseline vs Weighted Loss: Per-label F1 Comparison\n"
      ],
      "metadata": {
        "id": "Hv-gi1aBMaTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def per_label_f1(trainer, dataset, threshold=0.5):\n",
        "    pred_output = trainer.predict(dataset)\n",
        "    logits = pred_output.predictions\n",
        "    labels = pred_output.label_ids\n",
        "\n",
        "    probs = 1 / (1 + np.exp(-logits))\n",
        "    preds = (probs > threshold).astype(int)\n",
        "\n",
        "    f1s = f1_score(labels, preds, average=None, zero_division=0)\n",
        "    return f1s\n",
        "\n",
        "# Baseline model per-label F1\n",
        "baseline_f1s = per_label_f1(baseline_trainer, test_dataset, threshold=0.5)\n",
        "# Weighted model per-label F1\n",
        "weighted_f1s = per_label_f1(weighted_trainer, test_dataset, threshold=0.5)\n",
        "\n",
        "print(\"Baseline per-label F1:\")\n",
        "print(dict(zip(label_cols, baseline_f1s)))\n",
        "print(\"\\nWeighted per-label F1:\")\n",
        "print(dict(zip(label_cols, weighted_f1s)))\n"
      ],
      "metadata": {
        "id": "5w-WmsepMevR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Figure 1. Per-label F1 Comparison — Baseline vs Weighted Loss Model**\n",
        "\n",
        "Description:\n",
        "This bar chart compares the per-label F1 scores of the baseline DistilBERT model and the improved weighted-loss model. Labels with many training samples (toxic, obscene, insult) show similar performance across both models, as expected.\n",
        "However, the weighted-loss model significantly improves performance on minority classes:\n",
        "\n",
        "  -severe_toxic\n",
        "\n",
        "  -threat\n",
        "\n",
        "  -identity_hate\n",
        "\n",
        "These classes originally had very low F1 scores due to dataset imbalance. After applying class weights, the model becomes more sensitive to these rare but important toxicity categories.\n",
        "This validates that weighted BCE is an effective technique to reduce majority-class bias and improve detection of underrepresented labels."
      ],
      "metadata": {
        "id": "TpnW-y_VoLpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = label_cols\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x - width/2, baseline_f1s, width, label='Baseline')\n",
        "plt.bar(x + width/2, weighted_f1s, width, label='Weighted Loss')\n",
        "\n",
        "plt.xticks(x, labels, rotation=45)\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.title(\"Per-label F1: Baseline vs Weighted Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "816stYoGMif0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Figure 2. Baseline Model — Training vs Validation Loss Curve**\n",
        "\n",
        "Description:\n",
        "This figure shows how the DistilBERT baseline model’s loss changed during training. The blue line represents the training loss, and the orange line represents the validation loss. Both curves decrease steadily, indicating that the model is learning effectively. The small gap between training and validation loss suggests:\n",
        "\n",
        "-The model does not overfit\n",
        "\n",
        "-Training is stable\n",
        "\n",
        "-Two epochs were a good choice for this dataset\n",
        "\n",
        "This plot confirms that the baseline model converges properly before applying any improvements such as weighted loss."
      ],
      "metadata": {
        "id": "LI8fozzxnyVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "baseline_logs = pd.DataFrame(baseline_trainer.state.log_history)\n",
        "baseline_loss = baseline_logs[baseline_logs[\"loss\"].notna()]\n",
        "baseline_eval = baseline_logs[baseline_logs[\"eval_loss\"].notna()]\n",
        "plt.figure(figsize=(10,6))\n",
        "# training loss\n",
        "plt.plot(baseline_loss[\"step\"], baseline_loss[\"loss\"], label=\"Training Loss\")\n",
        "# validation loss\n",
        "plt.plot(baseline_eval[\"step\"], baseline_eval[\"eval_loss\"], label=\"Validation Loss\")\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Baseline Model — Training vs Validation Loss Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6OCucTXrkkJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}